{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sxIWW3siDIX"
      },
      "source": [
        "## Coding Quiz"
      ],
      "id": "6sxIWW3siDIX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMXUaBoFiDIa"
      },
      "source": [
        "With the given dataset, Please compare your best possible version of\n",
        "\n",
        "    (1) BiLSTM,\n",
        "    (2) BiLSTM with multiplicative attention (you have to fix e), and\n",
        "    (3) BERT\n",
        "\n",
        "Report the accuracy, precision, recall, and f1-score of each model.\n",
        "\n",
        "For (1) and (2), use the following hyperparameters:\n",
        "\n",
        "    Optimizer: SG\n",
        "    Embedding: GloVe (https://pytorch.org/text/stable/vocab.html#torchtext.vocab.GloVe) >> Please change the embed_dim accordingly.\n",
        "    Epochs: 2\n",
        "    Batch size: 32\n",
        "    Save the model with the best params\n",
        "\n",
        "Anything not stated, please assume accordingly\n",
        "\n",
        "\n",
        "For (2), Multiplicative attention differs from the General Attention (in Assignment 4) such that, for the *Alignment Scores* (or Energy), we multiply the Keys with some weights first before we dot the Keys with the Query.\n",
        "\n",
        "$\\mathbf{e}_i = \\mathbf{q}^T \\ \\mathbf{W}  \\mathbf{k}_t $\n",
        "\n",
        "where $ \\mathbf{W} \\in \\mathbb{R}^{h,h}$\n",
        "\n",
        "* Hint : The shape of the Keys before and after multiplying with the weights should be the same\n",
        "\n",
        "For (3), use this tutorial https://huggingface.co/docs/transformers/training as your guide."
      ],
      "id": "rMXUaBoFiDIa"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dmecyLQ_iDIb"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
      ],
      "id": "dmecyLQ_iDIb"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kv2R99AJiDIc",
        "outputId": "63ff2464-cfda-487d-d7c4-02d9c4731d3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torchtext\n",
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "id": "Kv2R99AJiDIc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-X63XRXiDId"
      },
      "source": [
        "#### 1. Load the IMDB Review dataset from TorchText (https://pytorch.org/text/stable/datasets.html#id10)"
      ],
      "id": "9-X63XRXiDId"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "# tokens = tokenizer(\"We are learning torchtext in U.K.!\")  #some test\n",
        "# tokens"
      ],
      "metadata": {
        "id": "G41iEK2V7yvk"
      },
      "id": "G41iEK2V7yvk",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "NvMMrR0P76yN"
      },
      "id": "NvMMrR0P76yN",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: 1 if x == 'pos' else 0\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence #++\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, length_list = [], [], []\n",
        "    for (_label, _text) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        length_list.append(processed_text.size(0))  #++<-----packed padded sequences require length\n",
        "    #criterion expects float labels\n",
        "    return torch.tensor(label_list, dtype=torch.float64), pad_sequence(text_list, padding_value=pad_idx, batch_first=True), torch.tensor(length_list, dtype=torch.int64)\n",
        "\n",
        "from torchtext.datasets import IMDB\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "\n",
        "batch_size = 32\n",
        "num_train = int(len(train_dataset) * 0.15)\n",
        "num_val = int(len(train_dataset) * 0.10)\n",
        "num_test = int(len(test_dataset) * 0.05)\n",
        "\n",
        "split_train_, split_valid_, _ = \\\n",
        "    random_split(train_dataset, [num_train, num_val,len(train_dataset)- num_train - num_val])\n",
        "\n",
        "split_test_, _ = \\\n",
        "    random_split(train_dataset, [num_test, len(test_dataset) - num_test])\n",
        "\n",
        "train_loader = DataLoader(split_train_, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(split_valid_, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(split_test_, batch_size=batch_size,\n",
        "                             shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "uYe_kAqUudn3"
      },
      "id": "uYe_kAqUudn3",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('valid',len(valid_loader))\n",
        "# print('train',len(train_loader))"
      ],
      "metadata": {
        "id": "sVRiskuuemU0"
      },
      "id": "sVRiskuuemU0",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchtext.vocab import FastText\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "glove_vector = torchtext.vocab.GloVe(name='6B', dim=300)\n",
        "fast_embedding = glove_vector.get_vecs_by_tokens(vocab.get_itos()).to(device)"
      ],
      "metadata": {
        "id": "JAj73Y5H860G"
      },
      "id": "JAj73Y5H860G",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(vocab)\n",
        "hidden_dim = 256\n",
        "embed_dim = 300\n",
        "output_dim = 1\n",
        "\n",
        "pad_idx = vocab['<pad>']\n",
        "num_layers = 2\n",
        "bidirectional = True\n",
        "dropout = 0.5\n",
        "\n",
        "\n",
        "num_epochs = 2\n",
        "lr=0.0001"
      ],
      "metadata": {
        "id": "u2LvEj0o8Tah"
      },
      "id": "u2LvEj0o8Tah",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explicitly initialize weights for better learning\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.RNN):\n",
        "        for name, param in m.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.zeros_(param)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.orthogonal_(param) #<---here\n",
        "                \n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "MimF7zW58VwV"
      },
      "id": "MimF7zW58VwV",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train() #useful for batchnorm and dropout\n",
        "    for i, (label, text, text_length) in enumerate(loader): \n",
        "        label = label.to(device) #(batch_size, )\n",
        "        text = text.to(device) #(batch_size, seq len)\n",
        "                \n",
        "        #predict\n",
        "        predictions = model(text, text_length) #output by the fc is (batch_size, 1), thus need to remove this 1\n",
        "        predictions = predictions.squeeze(1)\n",
        "        \n",
        "        #calculate loss\n",
        "        loss = criterion(predictions, label)\n",
        "        acc = binary_accuracy(predictions, label)\n",
        "        \n",
        "        #backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "        if i == 10:\n",
        "            break\n",
        "                \n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (label, text, text_length) in enumerate(loader): \n",
        "            label = label.to(device) #(batch_size, )\n",
        "            text = text.to(device) #(batch_size, seq len)\n",
        "\n",
        "            predictions = model(text, text_length)\n",
        "            predictions = predictions.squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, label)\n",
        "            acc = binary_accuracy(predictions, label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            \n",
        "            if i == 10:\n",
        "                break\n",
        "        \n",
        "    return epoch_loss / len(loader), epoch_acc / len(loader)"
      ],
      "metadata": {
        "id": "kXHWzWO28YgR"
      },
      "id": "kXHWzWO28YgR",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM"
      ],
      "metadata": {
        "id": "XWiMnzaA0GyD"
      },
      "id": "XWiMnzaA0GyD"
    },
    {
      "cell_type": "code",
      "source": [
        "class new_LSTM_cell(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, lstm_type: str):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_type = lstm_type\n",
        "        \n",
        "        # initialise the trainable Parameters\n",
        "        self.U_i = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
        "        self.W_i = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        self.b_i = nn.Parameter(torch.Tensor(hidden_dim))\n",
        "        \n",
        "        self.U_f = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
        "        self.W_f = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        self.b_f = nn.Parameter(torch.Tensor(hidden_dim))\n",
        "        \n",
        "        self.U_g = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
        "        self.W_g = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        self.b_g = nn.Parameter(torch.Tensor(hidden_dim))\n",
        "        \n",
        "        self.U_o = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
        "        self.W_o = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        self.b_o = nn.Parameter(torch.Tensor(hidden_dim))\n",
        "        \n",
        "        if self.lstm_type == 'peephole' :\n",
        "            self.P_i = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "            self.P_f = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "            self.P_o = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "            \n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_dim)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "    \n",
        "    def forward(self, x, init_states=None):\n",
        "        bs, seq_len, _ = x.shape\n",
        "        output = []\n",
        "        \n",
        "        # initialize the hidden state and cell state for the first time step \n",
        "        if init_states is None:\n",
        "            h_t  = torch.zeros(bs, self.hidden_dim).to(x.device)\n",
        "            c_t  = torch.zeros(bs, self.hidden_dim).to(x.device)\n",
        "        else:\n",
        "            h_t, c_t = init_states\n",
        "        \n",
        "        # For each time step of the input x, do ...\n",
        "        for t in range(seq_len):\n",
        "            x_t = x[:, t, :] # get x data of time step t (SHAPE: (batch_size, input_dim))\n",
        "            \n",
        "            if self.lstm_type in ['vanilla', 'coupled'] :\n",
        "                f_t = torch.sigmoid(    h_t @ self.W_f  +  x_t @ self.U_f  +  self.b_f)\n",
        "                o_t = torch.sigmoid(    h_t @ self.W_o  +  x_t @ self.U_o  +  self.b_o)\n",
        "                if self.lstm_type == 'vanilla':\n",
        "                    i_t = torch.sigmoid(    h_t @ self.W_i  +  x_t @ self.U_i  +  self.b_i)\n",
        "                if self.lstm_type == 'coupled':\n",
        "                    i_t = (1 - f_t)\n",
        "            if self.lstm_type == 'peephole' :\n",
        "                i_t = torch.sigmoid( h_t @ self.W_i + x_t @ self.U_i + c_t @ self.P_i + self.b_i) # SHAPE: (batch_size, hidden_dim)\n",
        "                f_t = torch.sigmoid( h_t @ self.W_f + x_t @ self.U_f + c_t @ self.P_f + self.b_f) # SHAPE: (batch_size, hidden_dim)\n",
        "                o_t = torch.sigmoid( h_t @ self.W_o + x_t @ self.U_o + c_t @ self.P_o + self.b_o) # SHAPE: (batch_size, hidden_dim)\n",
        "            \n",
        "            g_t = torch.tanh(       h_t @ self.W_g  +  x_t @ self.U_g   + self.b_g)\n",
        "            c_t = (f_t * c_t) + (i_t * g_t)\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "            \n",
        "            output.append(h_t.unsqueeze(0)) # reshape h_t to (1, batch_size, hidden_dim), then append to the list of hidden states\n",
        "\n",
        "        output = torch.cat(output, dim = 0) # concatenate h_t of all time steps into SHAPE :(seq_len, batch_size, hidden_dim)\n",
        "        output = output.transpose(0, 1).contiguous() # just transpose to SHAPE :(seq_len, batch_size, hidden_dim)\n",
        "        return output, (h_t, c_t)"
      ],
      "metadata": {
        "id": "yyZ8i-lv8a1R"
      },
      "id": "yyZ8i-lv8a1R",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_model(nn.Module):\n",
        "    def __init__(self, input_dim: int, embed_dim: int, hidden_dim: int, output_dim: int):\n",
        "        super().__init__()\n",
        "        self.num_directions = 2\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=pad_idx)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.forward_lstm   =  new_LSTM_cell(embed_dim, hidden_dim, lstm_type = 'vanilla')\n",
        "        self.backward_lstm  =  new_LSTM_cell(embed_dim, hidden_dim, lstm_type = 'vanilla')\n",
        "        \n",
        "        # These should be torch Parameters\n",
        "        self.W_h = nn.Parameter(torch.Tensor(hidden_dim*self.num_directions, hidden_dim*self.num_directions ))\n",
        "        self.b_h = nn.Parameter(torch.Tensor(hidden_dim*self.num_directions))\n",
        "        \n",
        "        self.fc  = nn.Linear(hidden_dim*self.num_directions, output_dim)\n",
        "    \n",
        "        self.init_weights()\n",
        "    \n",
        "    def init_weights(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_dim)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "    \n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded      = self.embedding(text)\n",
        "        embedded_flip =  torch.flip(embedded, [1]) \n",
        "        \n",
        "        output_forward, (hn_forward, cn_forward)    = self.forward_lstm(embedded, init_states=None)\n",
        "        output_backward, (hn_backward, cn_backward) = self.backward_lstm(embedded_flip, init_states=None)\n",
        "        \n",
        "        concat_hn = torch.cat( (hn_forward, hn_backward), dim=1 ) \n",
        "        ht        = torch.sigmoid( concat_hn @ self.W_h + self.b_h)\n",
        "\n",
        "        return self.fc(ht)"
      ],
      "metadata": {
        "id": "f8H7FoHK8dVu"
      },
      "id": "f8H7FoHK8dVu",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "bilstm = BiLSTM_model(input_dim, embed_dim, hidden_dim, output_dim).to(device)\n",
        "bilstm.apply(initialize_weights)\n",
        "bilstm.embedding.weight.data = fast_embedding\n",
        "\n",
        "optimizer = optim.SGD(bilstm.parameters(), lr=lr) \n",
        "criterion = nn.BCEWithLogitsLoss() #combine sigmoid with binary cross entropy\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(bilstm, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(bilstm, valid_loader, criterion)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accs.append(valid_acc)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(bilstm.state_dict(), 'BiLSTM-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "# del bilstm\n",
        "# del optimizer\n",
        "# del criterion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHmMSO3u8gVZ",
        "outputId": "1191cd31-0488-47ee-e645-6904fadf58c0"
      },
      "id": "NHmMSO3u8gVZ",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Train Loss: 0.069 | Train Acc: 4.98%\n",
            "\t Val. Loss: 0.106 |  Val. Acc: 7.08%\n",
            "Epoch: 02 | Train Loss: 0.074 | Train Acc: 4.26%\n",
            "\t Val. Loss: 0.101 |  Val. Acc: 7.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "bilstm.load_state_dict(torch.load('BiLSTM-model.pt'))\n",
        "test_loss, test_acc = evaluate(bilstm, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h3HVN990rxb",
        "outputId": "fd03db54-fbf1-4863-a099-35c12f868dfa"
      },
      "id": "0h3HVN990rxb",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.000 | Test Acc: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epoch_loss = 0\n",
        "epoch_acc = 0\n",
        "#bilstm = BiLSTM_model(input_dim, embed_dim, hidden_dim, output_dim).to(device)\n",
        "bilstm.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (label, text, text_length) in enumerate(train_loader): \n",
        "        label = label.to(device) #(batch_size, )\n",
        "        text = text.to(device) #(batch_size, seq len)\n",
        "\n",
        "        predictions = bilstm(text, text_length)\n",
        "        predictions = predictions.squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, label)\n",
        "        acc = binary_accuracy(predictions, label)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "       \n",
        "   "
      ],
      "metadata": {
        "id": "YDb_4NWAyVu0"
      },
      "id": "YDb_4NWAyVu0",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK5tZ8XZysWZ",
        "outputId": "53396e42-5e37-4c34-a55e-300f096f681a"
      },
      "id": "YK5tZ8XZysWZ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7532, -0.7532, -0.7532, -0.7532, -0.7532, -0.7532], device='cuda:0')\n",
            "tensor([1., 1., 1., 0., 1., 0.], device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion(prediction, truth):\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(prediction))\n",
        "    confusion_vector = rounded_preds / truth\n",
        "    true_positives = torch.sum(confusion_vector == 1).item()\n",
        "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
        "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
        "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
        "\n",
        "    return true_positives, false_positives, true_negatives, false_negatives"
      ],
      "metadata": {
        "id": "yjjEohTUfm3h"
      },
      "id": "yjjEohTUfm3h",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_positives, false_positives, true_negatives, false_negatives = confusion(predictions,label)"
      ],
      "metadata": {
        "id": "QPTWR2Z4xZ7y"
      },
      "id": "QPTWR2Z4xZ7y",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = true_positives + false_positives + true_negatives + false_negatives\n",
        "\n",
        "accuracy = (true_positives + true_negatives) / (total * 1.0)\n",
        "precision = (1.0 * true_positives) / (true_positives + false_positives)\n",
        "recall = (1.0 * true_positives) / (true_positives + false_negatives)\n",
        "f1 = 2.0 / ((1.0 / precision) + (1.0 / recall))"
      ],
      "metadata": {
        "id": "rqxITYo3zFVf"
      },
      "id": "rqxITYo3zFVf",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Attention"
      ],
      "metadata": {
        "id": "mAebHt6AED7-"
      },
      "id": "mAebHt6AED7-"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class LSTM_GAtt(nn.Module):\n",
        "    def __init__(self, input_dim: int, embed_dim: int, hidden_dim: int, output_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=pad_idx)\n",
        "        \n",
        "        # let's use pytorch's LSTM\n",
        "        self.lstm = nn.LSTM(embed_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=num_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        # Linear Layer for binary classification \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.W = nn.Parameter(torch.Tensor(batch_size, hidden_dim * 2,hidden_dim * 2))\n",
        "    def attention_net(self, lstm_output, hn):\n",
        "        \n",
        "        h_t      = hn.unsqueeze(2)\n",
        "        H_keys   = torch.clone(lstm_output)\n",
        "        H_values = torch.clone(lstm_output)\n",
        "        H_query = torch.clone(lstm_output)\n",
        "\n",
        "        # k_w = torch.bmm(H_keys, self.W)\n",
        "        #   #alignment_score = torch.bmm(h_t, k_w.transpose(1,2))  # SHAPE : (bs, seq_len, seq_len)\n",
        "        # alignment_score   = torch.bmm(k_w, h_t).squeeze(2) # SHAPE : (bs, seq_len, 1)\n",
        "        \n",
        "        #alignment_score   = torch.bmm(H_keys, h_t).squeeze(2) # SHAPE : (bs, seq_len, 1)\n",
        "        score = torch.bmm(H_keys, self.W)\n",
        "        # # score  = self.W @  H_keys\n",
        "        alignment_score = torch.bmm(score,h_t).squeeze(2)\n",
        "        # alignment_score = (torch.bmm(self.W, H_keys).squeeze(2)\n",
        "        \n",
        "        soft_attn_weights = F.softmax(alignment_score, 1) # SHAPE : (bs, seq_len, 1)\n",
        "        \n",
        "        context           = torch.bmm(H_values.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2) # SHAPE : (bs, hidden_size * num_directions)\n",
        "        \n",
        "        return context\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        embedded = self.embedding(text) # SHAPE : (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        lstm_output, (hn, cn) = self.lstm(embedded)\n",
        "        \n",
        "        # This is how we concatenate the forward hidden and backward hidden from Pytorch's BiLSTM\n",
        "        hn = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1)\n",
        "\n",
        "        attn_output = self.attention_net(lstm_output, hn)\n",
        "        \n",
        "        return self.fc(attn_output)\n"
      ],
      "metadata": {
        "id": "JKkDNRer8ii_"
      },
      "id": "JKkDNRer8ii_",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#m_attmodel = LSTM_GAtt(input_dim, embed_dim, hidden_dim, output_dim, len_reduction = 'mean').to(device)\n",
        "m_attmodel = LSTM_GAtt(input_dim, embed_dim, hidden_dim, output_dim).to(device)\n",
        "m_attmodel.apply(initialize_weights)\n",
        "m_attmodel.embedding.weight.data = fast_embedding\n",
        "\n",
        "optimizer = optim.SGD(m_attmodel.parameters(), lr=lr) #<----changed to Adam\n",
        "criterion = nn.BCEWithLogitsLoss() #combine sigmoid with binary cross entropy\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(m_attmodel, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(m_attmodel, valid_loader, criterion)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accs.append(valid_acc)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(m_attmodel.state_dict(), 'LSTMMultiAtt-model.pt')\n",
        "  \n",
        "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "# del g_attmodel\n",
        "# del optimizer\n",
        "# del criterion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i0-Uk2aALPn",
        "outputId": "ffe76441-038a-4d67-89fd-5bccaaf0abfa"
      },
      "id": "6i0-Uk2aALPn",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Train Loss: 0.065 | Train Acc: 4.90%\n",
            "\t Val. Loss: 0.096 |  Val. Acc: 7.87%\n",
            "Epoch: 02 | Train Loss: 0.065 | Train Acc: 4.40%\n",
            "\t Val. Loss: 0.096 |  Val. Acc: 7.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "m_attmodel.load_state_dict(torch.load('LSTMMultiAtt-model.pt'))\n",
        "test_loss, test_acc = evaluate(m_attmodel, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ybL9ljR036z",
        "outputId": "f8149ca6-2bba-46b9-8717-88952e984a6d"
      },
      "id": "3ybL9ljR036z",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.000 | Test Acc: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jKnGqTRi0QFm"
      },
      "id": "jKnGqTRi0QFm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion(prediction, truth):\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(prediction))\n",
        "    confusion_vector = rounded_preds / truth\n",
        "    true_positives = torch.sum(confusion_vector == 1).item()\n",
        "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
        "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
        "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
        "\n",
        "    return true_positives, false_positives, true_negatives, false_negatives"
      ],
      "metadata": {
        "id": "X45h9KXX0TAt"
      },
      "id": "X45h9KXX0TAt",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_positives, false_positives, true_negatives, false_negatives = confusion(predictions,label)"
      ],
      "metadata": {
        "id": "htCZ1l5J0Vpp"
      },
      "id": "htCZ1l5J0Vpp",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = true_positives + false_positives + true_negatives + false_negatives\n",
        "\n",
        "accuracy = (true_positives + true_negatives) / (total * 1.0)\n",
        "precision = (1.0 * true_positives) / (true_positives + false_positives)\n",
        "recall = (1.0 * true_positives) / (true_positives + false_negatives)\n",
        "f1 = 2.0 / ((1.0 / precision) + (1.0 / recall))"
      ],
      "metadata": {
        "id": "tNDXZPtW0Ygp"
      },
      "id": "tNDXZPtW0Ygp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT"
      ],
      "metadata": {
        "id": "qqTbv_e3EHgG"
      },
      "id": "qqTbv_e3EHgG"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmpKBzGwACzp",
        "outputId": "2d8007c0-1e74-435d-e2cb-4cf36d7a3613"
      },
      "id": "bmpKBzGwACzp",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### BERT\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TrainingArguments\n",
        "#from transformers import DistilBertTokenizerFast\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "print(tokenizer)\n",
        "\n",
        "\n",
        "#tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# tokenized_train_datasets = train_dataset.map(tokenize_function)\n",
        "# tokenized_test_datasets = test_dataset.map(tokenize_function, b)"
      ],
      "metadata": {
        "id": "cEsQ7iY4_tEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ba938e-119d-4bfa-9ecb-566fa82388c5"
      },
      "id": "cEsQ7iY4_tEz",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PreTrainedTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA1uORcoZR8f",
        "outputId": "30dc30b5-0b88-4622-c348-e6db695f5dce"
      },
      "id": "yA1uORcoZR8f",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdpu6N3oV4-Z",
        "outputId": "0c8fc42c-1f93-4e62-e956-12ca1e3ba15b"
      },
      "id": "jdpu6N3oV4-Z",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PreTrainedTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(\"We are learning torchtext in U.K.!\")  #some test\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v99-ITkIWHv_",
        "outputId": "5133e0a0-1e04-4884-fbd1-471c6f35a4ca"
      },
      "id": "v99-ITkIWHv_",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1284, 1132, 3776, 16328, 17380, 1107, 158, 119, 148, 119, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_datasets = train_dataset.map(tokenize_function)\n",
        "tokenized_test_datasets = test_dataset.map(tokenize_function)"
      ],
      "metadata": {
        "id": "mcGuug5XWwUG"
      },
      "id": "mcGuug5XWwUG",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZjz7YF3tY2t",
        "outputId": "e4ab3dba-b711-4875-b8b8-d17090ceba9f"
      },
      "id": "CZjz7YF3tY2t",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_train_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYMcivWrhxUI",
        "outputId": "dddefc26-7916-4511-8017-16404d6d5f0b"
      },
      "id": "VYMcivWrhxUI",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.datapipes.map.callable.MapperMapDataPipe object at 0x7f98d3c7abd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNe8r1VSgYE0",
        "outputId": "84f2bc48-3a76-41f1-84ce-efa73f24e67a"
      },
      "id": "zNe8r1VSgYE0",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torchtext.data.functional.to_map_style_dataset.<locals>._MapStyleDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\")"
      ],
      "metadata": {
        "id": "PaAuD70QabtI"
      },
      "id": "PaAuD70QabtI",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "\n",
        "# bert = model(input_dim, embed_dim, hidden_dim, output_dim).to(device)\n",
        "# bert.apply(initialize_weights)\n",
        "# bert.embedding.weight.data = fast_embedding\n",
        "\n",
        "# optimizer = optim.SGD(bert.parameters(), lr=lr) \n",
        "# criterion = nn.BCEWithLogitsLoss() #combine sigmoid with binary cross entropy\n",
        "\n",
        "# train_losses = []\n",
        "# train_accs = []\n",
        "# valid_losses = []\n",
        "# valid_accs = []\n",
        "# best_valid_loss = float('inf')\n",
        "\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     train_loss, train_acc = train(bert, train_loader, optimizer, criterion)\n",
        "#     valid_loss, valid_acc = evaluate(bert, valid_loader, criterion)\n",
        "    \n",
        "#     train_losses.append(train_loss)\n",
        "#     train_accs.append(train_acc)\n",
        "#     valid_losses.append(valid_loss)\n",
        "#     valid_accs.append(valid_acc)\n",
        "\n",
        "#     if valid_loss < best_valid_loss:\n",
        "#         best_valid_loss = valid_loss\n",
        "#         torch.save(bilstm.state_dict(), 'bert-model.pt')\n",
        "    \n",
        "#     print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "    "
      ],
      "metadata": {
        "id": "qqB9C46RdpVg"
      },
      "id": "qqB9C46RdpVg",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.to(device)\n",
        "# model.train()"
      ],
      "metadata": {
        "id": "qKjGgKtJbJXX"
      },
      "id": "qKjGgKtJbJXX",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.sgd import SGD\n",
        "optim = SGD(model.parameters(), lr = 5e-5)"
      ],
      "metadata": {
        "id": "1GH-Lt-Bbd5m"
      },
      "id": "1GH-Lt-Bbd5m",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.eval()"
      ],
      "metadata": {
        "id": "STmrT2WZfPvn"
      },
      "id": "STmrT2WZfPvn",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for step, batch in enumerate(train_loader): \n",
        "\n",
        "  #for batch in train_loader:\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    outputs = model(input_ids, attention_mask = attention_mask,labels=labels )\n",
        "\n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "eFeF7pdHbjDa",
        "outputId": "329aad2c-7c14-461d-8a8e-9b8f90a26531"
      },
      "id": "eFeF7pdHbjDa",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-8496c87ac3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#for batch in train_loader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-481ca85b07da>\u001b[0m in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprocessed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtext_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlength_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#++<-----packed padded sequences require length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-481ca85b07da>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pos'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequence\u001b[0m \u001b[0;31m#++\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab/vocab.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mindices\u001b[0m \u001b[0massociated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: lookup_indices(): incompatible function arguments. The following argument types are supported:\n    1. (self: torchtext._torchtext.Vocab, arg0: list) -> List[int]\n\nInvoked with: <torchtext._torchtext.Vocab object at 0x7f995daaccf0>, {'input_ids': [101, 1409, 1128, 1176, 5367, 5558, 1114, 7424, 1104, 1892, 1105, 1301, 1874, 117, 5606, 1104, 5152, 118, 13671, 4899, 1105, 8362, 9261, 3452, 1158, 117, 13936, 7867, 3798, 4429, 1104, 4252, 1665, 5082, 26346, 1473, 117, 1173, 1440, 6890, 119, 1409, 1128, 1176, 3589, 117, 6601, 1183, 117, 17873, 5367, 1134, 27486, 1892, 4783, 1107, 5010, 1104, 170, 10416, 2296, 1104, 18410, 117, 1173, 23158, 22039, 1110, 1111, 1128, 119, 133, 9304, 120, 135, 133, 9304, 120, 135, 15255, 2365, 117, 13713, 1149, 1667, 117, 1117, 15604, 21155, 23516, 17449, 2050, 1676, 4246, 1105, 1147, 1685, 1488, 7726, 1132, 5312, 1149, 1106, 1103, 4883, 1183, 11408, 1111, 170, 1263, 5138, 12020, 1283, 1121, 1103, 1331, 119, 1212, 1103, 1236, 1146, 117, 1667, 4919, 170, 188, 21365, 1114, 1117, 1610, 119, 1109, 13202, 1150, 1125, 1151, 12137, 1103, 10064, 1132, 1136, 17278, 1165, 1152, 1525, 1115, 1667, 1144, 2207, 1147, 9839, 119, 1130, 2440, 117, 4167, 4993, 1174, 11151, 20579, 2274, 1122, 7572, 119, 1124, 3226, 1103, 1266, 1106, 1147, 12020, 1313, 117, 1543, 1612, 1152, 1267, 1140, 119, 1124, 21761, 1113, 1667, 1105, 4246, 1112, 1152, 1138, 2673, 119, 1124, 8966, 1194, 1147, 3751, 1114, 1117, 6658, 1165, 1152, 4597, 112, 189, 1313, 117, 5074, 1172, 7290, 1103, 26858, 7996, 1107, 1147, 3751, 1105, 2928, 1165, 1152, 1862, 119, 1332, 4246, 2274, 7726, 1106, 1103, 5557, 24612, 1107, 1411, 117, 7726, 1110, 5666, 1106, 170, 1353, ..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "piv0iOg1WOpk"
      },
      "id": "piv0iOg1WOpk",
      "execution_count": 63,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "CodingQuiz.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}